# LSCEngine - Reconocimiento de Lengua de Signos Colombiana (LSC)

Sistema de reconocimiento de gestos en Lengua de Signos Colombiana usando MediaPipe para extracciÃ³n de landmarks y redes neuronales BiLSTM con PyTorch.

## ğŸ“‹ DescripciÃ³n del Proyecto

LSCEngine es un pipeline completo para:
1. **ExtracciÃ³n de landmarks**: Usar MediaPipe para detectar puntos clave de manos en video
2. **Preprocesamiento**: Normalizar secuencias de landmarks y generar dataset pickle
3. **Entrenamiento**: Entrenar modelo BiLSTM bidireccional con data augmentation
4. **OptimizaciÃ³n**: BÃºsqueda de hiperparÃ¡metros con K-fold cross-validation
5. **Inferencia**: Generar Landmarks de seÃ±a

## ğŸ—ï¸ Arquitectura del Modelo

**Modelo: BiLSTM (Bidirectional LSTM)**

```
Entrada (6 frames Ã— 21 landmarks Ã— 3 coords = 6Ã—63)
    â†“
BiLSTM (512 hidden dims Ã— 3 capas, bidireccional â†’ 1024 caracterÃ­sticas)
    â†“
Linear (1024 â†’ 512)
    â†“
ReLU Activation
    â†“
Linear (512 â†’ num_classes)
    â†“
Salida (probabilidades por clase)
```

**HiperparÃ¡metros Ã³ptimos (encontrados en `hyper.py`):**
- Learning Rate: 0.001
- Hidden Dimension: 512
- Num Layers: 3
- Batch Size: 32
- Accuracy: ~80.3%

## ğŸ“ Estructura de Archivos

```
LSCEngine/
â”œâ”€â”€ README.md                    # Este archivo
â”œâ”€â”€ requirements.txt             # Dependencias del proyecto
â”‚
â”œâ”€â”€ 1ï¸âƒ£ preprocess.py             # [PASO 1] Extraer landmarks con MediaPipe
â”œâ”€â”€ preprocessed/                # Datos preprocesados (generado automÃ¡ticamente)
â”‚   â””â”€â”€ sequences_all.pkl        # Dataset serializado con landmarks
â”‚
â”œâ”€â”€ dataset_lsc_landmarks.py     # Dataset PyTorch + normalizaciÃ³n + augmentation
â”œâ”€â”€ model_and_loader2.py         # DefiniciÃ³n del modelo BiLSTM
â”‚
â”œâ”€â”€ 2ï¸âƒ£ hyper.py                  # [PASO 2] BÃºsqueda de hiperparÃ¡metros (opcional)
â”œâ”€â”€ 3ï¸âƒ£ train_with_validation.py  # [PASO 3] Entrenamiento con validaciÃ³n 
â”‚
â”œâ”€â”€ infer_biLSTM.py              # [PASO 4] Inferencia: GeneraciÃ³n de Landmarks segÃºn texto ingresado
â”‚
â”œâ”€â”€ models/                      # Modelos guardados
â”‚   â””â”€â”€ best_biLSTM_model.pth
â”‚
â””â”€â”€ results/                     # Resultados de experimentos
    â””â”€â”€ accuracy_plot.jpg
```

## ğŸš€ Orden de EjecuciÃ³n

### **OpciÃ³n A: Pipeline Completo (Recomendado)**

#### 1. Instalar dependencias
```bash
pip install -r requirements.txt
```

#### 2. Preprocesar dataset (extraer landmarks)
```bash
python preprocess.py
```
- Lee imÃ¡genes de `LSC70/`
- Extrae landmarks de manos con MediaPipe
- Genera `preprocessed/sequences_all.pkl`
- 

#### 3. Entrenar modelo (opcional: primero optimizar hiperparÃ¡metros)
```bash
# Opcional: bÃºsqueda de hiperparÃ¡metros (mÃ¡s lento)
python hyper.py

# O entrenar directamente con hiperparÃ¡metros Ã³ptimos
python train_with_validation.py
```
- Entrena BiLSTM con validaciÃ³n 80/20
- Early stopping si no mejora en 10 Ã©pocas
- Guarda mejor modelo en `best_biLSTM_model.pth`
-

#### 4. Generar Landmarks a partir de texto
```bash
python infer_biLSTM.py
```

- Genera GIFs con predicciones (`sign_*.gif`)

---

### **OpciÃ³n B: Solo Inferencia (Si ya tienes modelo entrenado)**
```bash
python infer_biLSTM.py
```
- Necesita `best_biLSTM_model.pth` existente
- No requiere preprocesamiento ni entrenamiento

---

## âš™ï¸ ConfiguraciÃ³n

### Variables principales en scripts:

**`train_with_validation.py`:**
```python
PKL_PATH = "c:/IA_CarlosMartinez/preprocessed/sequences_all.pkl"  # Ruta a dataset
BATCH_SIZE = 32          # TamaÃ±o de lote
LR = 0.001               # Learning rate
EPOCHS = 100             # Ã‰pocas mÃ¡ximas
HIDDEN_DIM = 512         # DimensiÃ³n LSTM
NUM_LAYERS = 3           # Capas LSTM
DEVICE = "cuda" or "cpu" # GPU automÃ¡tica si disponible
```

**`preprocess.py`:**
```python
DATASET_ROOT = r"C:\IA_CarlosMartinez\LSC70\LSC70"  # Ruta dataset raw
OUT_FILE = "preprocessed/sequences_all.pkl"         # Salida
SEQUENCE_LENGTH = 6      # Frames por secuencia
```

## ğŸ“Š Datos de Entrada

**Dataset LSC70:**
- 3 variantes: LSC70AN, LSC70ANH, LSC70W
- Estructura: `Variante/Persona/Clase/ImÃ¡genes(6 frames de seÃ±a)`
- ~47 clases (gestos/palabras diferentes)

**Formato de landmarks:**
- 21 puntos por mano (MediaPipe Hands)
- Coordenadas: (x, y, z) normalizadas [0, 1]
- Entrada modelo: (batch_size, seq_len=6, 21*3=63)

## ğŸ“ˆ Resultados

**Mejor modelo encontrado:**
- **Accuracy**: 80.3%
- **ConfiguraciÃ³n**: lr=0.001, hidden_dim=512, num_layers=3, batch_size=32
- **Dataset**: 80% entrenamiento, 20% validaciÃ³n

## ğŸ› ï¸ Troubleshooting

### Error: "OOM (Out of Memory)"
- Reducir `BATCH_SIZE` (e.g., 32 â†’ 16)
- Reducir `HIDDEN_DIM` (e.g., 512 â†’ 256)
- Usar GPU: `pip install torch --index-url https://download.pytorch.org/whl/cu118`

### Error: "No module named 'mediapipe'"
```bash
pip install mediapipe
```

### Error: "File not found: sequences_all.pkl"
- Ejecutar primero `python preprocess.py`

### Modelo entrenado lentamente
- Habilitar GPU si disponible: `torch.cuda.is_available()`
- Ejecutar en mÃ¡quina con mÃ¡s cores CPU

## ğŸ“š Dependencias Principales

| LibrerÃ­a | VersiÃ³n | Uso |
|----------|---------|-----|
| `torch` | â‰¥2.0 | Framework deep learning |
| `torchvision` | â‰¥0.15 | Utilitarios visiÃ³n |
| `mediapipe` | â‰¥0.10 | ExtracciÃ³n landmarks |
| `opencv-python` | â‰¥4.8 | Procesamiento video |
| `numpy` | â‰¥1.24 | Operaciones numÃ©ricas |
| `scikit-learn` | â‰¥1.2 | Train/val split |
| `matplotlib` | â‰¥3.7 | VisualizaciÃ³n |
| `tqdm` | â‰¥4.66 | Barras de progreso |

Ver `requirements.txt` para versiones exactas.

## ğŸ“ Notas

- **Preprocesamiento costoso**: Se ejecuta una sola vez; el resultado se cachea en `.pkl`
- **Data augmentation**: Solo aplicada a entrenamiento, no a validaciÃ³n
- **Device automÃ¡tico**: Usa GPU si `torch.cuda.is_available()`, else CPU


## ğŸ‘¨â€ğŸ’» Autor

**Carlos Mario MartÃ­nez GÃ³mez**
- GitHub: [@CarlosMMartinezG](https://github.com/CarlosMMartinezG)
- Proyecto: Reconocimiento de Lengua de Signos Colombiana

